{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX Interface Demo\n",
    "\n",
    "To be clarified:\n",
    "- How to interpret onnx outputs named ...*sigmoid*...\n",
    "- Where are the bounding boxes?\n",
    "- Where is Michael's code for the other models FasterRCNN, ...\n",
    "- Michael's thesis literature?\n",
    "\n",
    "Demo showing how to interface YOLO with the ONNX framework.\n",
    "\n",
    "Packages are availabe under conda environment 'yolov5'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load YOLO and prepare\n",
    "Make sure that we are in conda environment 'yolov5' !!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import importlib.util\n",
    "#import json\n",
    "import os\n",
    "import ast\n",
    "\n",
    "import yolov5\n",
    "from yolov5 import YOLOv5\n",
    "#from yolov5 import export  # does not work\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import onnxruntime\n",
    "import onnx\n",
    "from onnx import numpy_helper\n",
    "\n",
    "\n",
    "home_dir = os.getcwd()\n",
    "data_dir = home_dir + '/../data'\n",
    "\n",
    "# Import yolo's prediction app (detect.py) manually\n",
    "pred_app_path = os.path.dirname(yolov5.__file__) + '/detect.py'\n",
    "pred_spec = importlib.util.spec_from_file_location('detect', pred_app_path)\n",
    "detect = importlib.util.module_from_spec(pred_spec)\n",
    "pred_spec.loader.exec_module(detect)\n",
    "\n",
    "# Import yolo's export app\n",
    "exp_app_path = os.path.dirname(yolov5.__file__) + '/export.py'\n",
    "exp_spec = importlib.util.spec_from_file_location('export', exp_app_path)\n",
    "export = importlib.util.module_from_spec(exp_spec)\n",
    "exp_spec.loader.exec_module(export)\n",
    "\n",
    "\n",
    "# Load the trained model\n",
    "#model = YOLOv5(data_dir + '/model/pen-parts/weights/best.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select model dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'planets-gearbox'\n",
    "\n",
    "# Image size needs to correspond to the model and should be looked up manually.\n",
    "image_size = (928,928)\n",
    "\n",
    "pt_model_path = os.path.join(data_dir, 'model', dataset_name, 'weights/best.pt')\n",
    "metadata_path = os.path.join(data_dir, 'training', dataset_name, 'data.yml') \n",
    "valid_images_dir = os.path.join(data_dir, 'training', dataset_name, 'valid/images')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a prediction with YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify YOLO's prediction locations \n",
    "prediction_output_path = os.path.join(data_dir, 'prediction')\n",
    "\n",
    "# Run with YOLO\n",
    "detect.run(weights=pt_model_path, \n",
    "           source=valid_images_dir, \n",
    "           data=metadata_path,\n",
    "           imgsz=image_size,\n",
    "           conf_thres=0.25, \n",
    "           project=prediction_output_path, \n",
    "           name=dataset_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert YOLO model from pt to onnx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export using the export app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spcify export parameters\n",
    "batch_size = 1 # num of images to be processed in one run\n",
    "exp_format = ['onnx']\n",
    "opset_version = 10 # the ONNX version to use for export\n",
    "use_dynamic = True # do not allow variable image size as input\n",
    "use_simplify = True # do not use the onnx simplifier\n",
    "\n",
    "#image_size = (900,900)\n",
    "\n",
    "# Export with YOLO\n",
    "console_out = export.run(data=metadata_path,\n",
    "           weights=pt_model_path,\n",
    "           imgsz=image_size,\n",
    "           batch_size=batch_size,\n",
    "           opset=opset_version,\n",
    "           include=exp_format,\n",
    "           dynamic=use_dynamic,\n",
    "           simplify=use_simplify)\n",
    "\n",
    "onnx_model_path = Path(pt_model_path).with_suffix('.onnx')\n",
    "\n",
    "print(f\"\\nModel exportet to: {onnx_model_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "DEPRECATED",
     "Do not run"
    ]
   },
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "# This will be the (fixed) format for predictions with the exported model.\n",
    "# Use the same format as the one for the training images.\n",
    "batch_size = 1 # num of images to be processed in one run\n",
    "trace_im = (torch.randn(batch_size, 3, image_size[0], image_size[1], requires_grad=False),)\n",
    "\n",
    "file_export = Path('plantes-gearbox.onnx') # filename as pathlib object\n",
    "opset_version = 10 # the ONNX version to use for export\n",
    "use_dynamic = False # do not allow variable image size as input\n",
    "use_simplify = False # do not use the onnx simplifier\n",
    "\n",
    "# Export the model to ONNX\n",
    "export.export_onnx(model.model, trace_im, file_export, opset_version, use_dynamic, use_simplify) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a prediction with onnx runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some helpers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(input_data):\n",
    "    # convert the input data into the float32 input\n",
    "    img_data = input_data.astype('float32')\n",
    "\n",
    "    #normalize\n",
    "    mean_vec = np.array([0.485, 0.456, 0.406])\n",
    "    stddev_vec = np.array([0.229, 0.224, 0.225])\n",
    "    norm_img_data = np.zeros(img_data.shape).astype('float32')\n",
    "    for i in range(img_data.shape[0]):\n",
    "        norm_img_data[i,:,:] = (img_data[i,:,:]/255 - mean_vec[i]) / stddev_vec[i]\n",
    "        \n",
    "    #add batch channel\n",
    "    norm_img_data = norm_img_data.reshape(1, 3, image_size[0], image_size[1]).astype('float32')\n",
    "    return norm_img_data\n",
    "\n",
    "def softmax(x):\n",
    "    x = x.reshape(-1)\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "def postprocess(result):\n",
    "    return softmax(np.array(result)).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model and runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = onnxruntime.InferenceSession(onnx_model_path, None)\n",
    "\n",
    "# get the name of the first input of the model\n",
    "input_name = session.get_inputs()[0].name\n",
    "labels_string = session.get_modelmeta().custom_metadata_map['names']\n",
    "labels = ast.literal_eval(labels_string)\n",
    "model_output = session.get_outputs()\n",
    "\n",
    "#print('Input name:', input_name)\n",
    "\n",
    "print(\"Input names: \", end='')\n",
    "for inp in session.get_inputs(): print(inp.name, \" \", end='')\n",
    "\n",
    "print(f\"\\nLabels: {list(labels.values())}\")\n",
    "\n",
    "print(\"Ouput names: \", end='')\n",
    "for out in model_output:\n",
    "    print(out.name, \" \", end='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in one of the example images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = load_labels('imagenet-simple-labels.json')\n",
    "\n",
    "#example_image_name = '/Video1_8_jpg.rf.815eb1fbb012e439b92e7c0c7cb93b0f.jpg'\n",
    "example_image_name = '/1_928.jpg'\n",
    "\n",
    "image = Image.open(valid_images_dir + example_image_name)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "#plt.imshow(image)\n",
    "print(f\"Image size: {image.size}\")\n",
    "\n",
    "image_data = np.array(image).transpose(2, 0, 1)\n",
    "input_data = preprocess(image_data)\n",
    "\n",
    "print(f\"Image shape: {image_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_result = session.run([], {input_name: input_data})\n",
    "res = postprocess(raw_result[0][0][0].tolist())\n",
    "\n",
    "# Analyse output data structure\n",
    "print(\"Output data format:\")\n",
    "for i in [0,1,2,3]:\n",
    "    print(f\"{model_output[i].name}: {raw_result[i].shape}\")\n",
    "\n",
    "print(raw_result[0][0].shape)\n",
    "\n",
    "raw_result[0][0].transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interprete inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argmax(res)\n",
    "\n",
    "print('Final top prediction is: ' + labels[idx])\n",
    "#print('\\n')\n",
    "\n",
    "sort_idx = np.flip(np.squeeze(np.argsort(res)))\n",
    "print('Top 5 labels are:')\n",
    "print(list(map(labels.get, sort_idx[:5])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
